{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8a9d182f",
   "metadata": {},
   "source": [
    "Realizamos los imports necesarios e iniciamos una SparkSession"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "033825a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.5` \n",
    "import $ivy.`sh.almond::almond-spark:0.4.0`\n",
    "\n",
    "import org.apache.spark.sql.{NotebookSparkSession, SparkSession}\n",
    "import org.apache.spark.sql.{functions => func, _}\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val spark = NotebookSparkSession\n",
    "      .builder()\n",
    "      .config(\"spark.sql.join.preferSortMergeJoin\", false)\n",
    "      //.config(\"spark.sql.shuffle.partitions\", 64)\n",
    "      .master(\"local[*]\")\n",
    "      .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "import org.slf4j.LoggerFactory\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "\n",
    "Logger.getRootLogger().setLevel(Level.ERROR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1f4e9899",
   "metadata": {},
   "outputs": [],
   "source": [
    "val data: DataFrame = spark.read.option(\"multiline\", \"true\").json(\"D:/TFGAlvaroSanchez/data2/*.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d95437a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e2ac2a2",
   "metadata": {},
   "source": [
    "### Obtencion de la fecha y del valor maximo de temperatura"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4590aee",
   "metadata": {},
   "source": [
    "Con lo siguiente cambiamos el tipo de datos de la columna ta_max\n",
    "\n",
    "val data1 = data.withColumn(\"ta_max\", $\"ta_max\".substr(0,4).cast(IntegerType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e9d8457",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.{min, max, desc}\n",
    "\n",
    "data.withColumn(\"ta_max\", $\"ta_max\".substr(0,4).cast(IntegerType))\n",
    "    .select($\"fecha\", $\"ta_max\" as \"temperatura maxima\")\n",
    "    .orderBy($\"ta_max\".desc)\n",
    "    .show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cfd3f1",
   "metadata": {
    "scrolled": true
   },
   "source": [
    "### Obtencion del mes, año, id estacion y provincia donde ocurren la stemperaturas mas altas en 2021"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bf439ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "val data2021 : DataFrame = spark.read.option(\"multiline\", \"true\").json(\"D:/TFGAlvaroSanchez/data2/*2021.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0832bdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2021.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab2f3ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2021.select($\"ta_min\", $\"indicativo\", $\"fecha\")\n",
    "    .filter($\"indicativo\".equalTo(\"2916A\"))\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f1c8194",
   "metadata": {},
   "source": [
    "Usamos `.df` para darle nombre a las columnas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a9dff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "val ids : DataFrame = spark.read.option(\"delimiter\", \";\").csv(\"D:/TFGAlvaroSanchez/data2/aemetID.csv\")\n",
    "    .toDF(\"provincia\", \"indicativo\", \"ubicacion\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65177ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "ids.show()\n",
    "ids.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baff4489",
   "metadata": {},
   "outputs": [],
   "source": [
    "val joindata : DataFrame = data2021.join(ids, \"indicativo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c5ed324",
   "metadata": {},
   "outputs": [],
   "source": [
    "joindata.withColumn(\"ta_max\", $\"ta_max\".substr(0,4).cast(IntegerType))\n",
    "    .select($\"fecha\".substr(6,2) as \"mes\", $\"fecha\".substr(0,4) as \"año\", $\"ta_max\" as \"temperatura maxima\", $\"indicativo\", $\"provincia\")\n",
    "    .filter(!($\"mes\".equalTo(\"13\")))\n",
    "    .orderBy($\"ta_max\".desc)\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2092bd58",
   "metadata": {},
   "source": [
    "### Obtencion del mes, año y provincia donde se encuntra la temperatura mas baja durante verano (junio, julio y agosto)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e978f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "joindata.withColumn(\"ta_min\", $\"ta_min\".substr(0,4).cast(IntegerType))\n",
    "    .withColumn(\"fecha\", $\"fecha\".cast(DateType)).printSchema"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8bb5c5d",
   "metadata": {},
   "source": [
    "Para quedarnos unicamente con la temperatura ya que este valor viene precedido del dia que ocurrio de la siguiente manera: temperatura(dia)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "050e2569",
   "metadata": {},
   "outputs": [],
   "source": [
    "import org.apache.spark.sql.functions.split\n",
    "\n",
    "joindata.withColumn(\"ta_min\", split($\"ta_min\", \"\\\\(\"))\n",
    "    .select($\"ta_min\"(0) as \"val\")\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8858f9f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "joindata.withColumn(\"ta_min\", split($\"ta_min\", \"\\\\(\"))\n",
    "    .withColumn(\"ta_min\", $\"ta_min\"(0).cast(IntegerType))\n",
    "    .withColumn(\"fecha\", $\"fecha\".cast(DateType))\n",
    "    .select(func.month($\"fecha\") as \"mes\", func.year($\"fecha\") as \"año\", $\"ta_min\" as \"temperatura minima\", $\"provincia\")  \n",
    "    .filter($\"mes\" > 5 && $\"mes\" < 9)\n",
    "    .orderBy($\"temperatura minima\".asc)\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7c3c3a",
   "metadata": {},
   "source": [
    "### Numero de meses con temperaturas maximas >30º por provincia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b906329d",
   "metadata": {},
   "outputs": [],
   "source": [
    "joindata\n",
    "    .withColumn(\"ta_max\", split($\"ta_max\", \"\\\\(\"))\n",
    "    .withColumn(\"ta_max\", $\"ta_max\"(0).cast(IntegerType))\n",
    "    .withColumn(\"fecha\", $\"fecha\".cast(DateType))\n",
    "    .filter($\"ta_max\" > 30 && !func.isnull($\"fecha\"))//> \"0000-00-00\")\n",
    "    .groupBy(\"provincia\")\n",
    "    .count\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "487e5b9f",
   "metadata": {},
   "source": [
    "Relacion que tiene el calor con los meses de verano"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1618d64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "joindata\n",
    "    .withColumn(\"ta_max\", split($\"ta_max\", \"\\\\(\"))\n",
    "    .withColumn(\"ta_max\", $\"ta_max\"(0).cast(IntegerType))\n",
    "    .withColumn(\"fecha\", $\"fecha\".cast(DateType))\n",
    "    .filter($\"ta_max\" > 30 && !func.isnull($\"fecha\"))\n",
    "    .withColumn(\"mes\", func.month($\"fecha\"))\n",
    "    .stat.corr(\"ta_max\", \"mes\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7aeb5b87",
   "metadata": {},
   "source": [
    "### Uso de graficos mostrando la precipitacion mensual por meses y años en Vitigudino(Salamanca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a8b4af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val vitData : DataFrame = spark.read.option(\"multiline\", \"true\").json(\"D:/TFGAlvaroSanchez/data2/2916A*.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "350a615c",
   "metadata": {},
   "source": [
    "Obtenemos los datos que queremos mostrar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07797cc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val vitDataRequired : DataFrame = vitData\n",
    "    .withColumn(\"fecha\", $\"fecha\".cast(DateType))\n",
    "    .withColumn(\"p_mes\", $\"p_mes\".cast(IntegerType))\n",
    "    .filter(!func.isnull($\"fecha\") && $\"p_mes\" >= 0)\n",
    "    .select($\"fecha\", $\"p_mes\")\n",
    "    .orderBy($\"fecha\".asc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82b379bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "vitDataRequired.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "018ab268",
   "metadata": {},
   "outputs": [],
   "source": [
    "val vitDataRequired_f : Seq[String] = vitDataRequired.select($\"fecha\").as[String].collect.toSeq\n",
    "val vitDataRequired_p : Seq[Int] = vitDataRequired.select($\"p_mes\").as[Int].collect.toSeq"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d4d0df",
   "metadata": {},
   "source": [
    "Realizamos los imports necesarios para las graficas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0250437",
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.plotly-scala::plotly-almond:0.7.0`\n",
    "import plotly._, plotly.element._, plotly.layout._, plotly.Almond._\n",
    "\n",
    "// restrict the output height to avoid scrolling in output cells\n",
    "repl.pprinter() = repl.pprinter().copy(defaultHeight = 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdaca6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "val trace = Seq(\n",
    "    Scatter(\n",
    "        vitDataRequired_f,\n",
    "        vitDataRequired_p,\n",
    "        fill = Fill.ToZeroY,\n",
    "        marker = Marker(\n",
    "            color = Color.RGBA(55, 128, 191, 0.6)\n",
    "        )\n",
    "    )\n",
    ")\n",
    "\n",
    "\n",
    "val layout = Layout(\n",
    "    title = \"Precipitacion mensual (mm)\",\n",
    "    paper_bgcolor =  Color.RGBA(245, 246, 249, 1),\n",
    "    plot_bgcolor = Color.RGBA(245, 246, 249, 1),\n",
    ")\n",
    "plot(trace, layout)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99e19237",
   "metadata": {},
   "source": [
    "### Leer los datos de manera casteada mediante un schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e77730d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "val schema = StructType(\n",
    "                Array(\n",
    "                    /*StructField(\"fecha\", DateType, true),\n",
    "                    StructField(\"indicativo\", StringType, true),\n",
    "                    StructField(\"p_max\", StringType, true),*/\n",
    "                    StructField(\"glo\", IntegerType, true),\n",
    "                    /*StructField(\"hr\", IntegerType, true),\n",
    "                    StructField(\"nw_55\", IntegerType, true),\n",
    "                    StructField(\"tm_min\", DoubleType, true),\n",
    "                    StructField(\"ta_max\", StringType, true),\n",
    "                    StructField(\"ts_min\", DoubleType, true),\n",
    "                    StructField(\"nt_30\", IntegerType, true),\n",
    "                    StructField(\"n_des\", IntegerType, true),\n",
    "                    StructField(\"w_racha\", StringType, true),\n",
    "                    StructField(\"np_100\", IntegerType, true)*/\n",
    "                )\n",
    "            )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bb25a98",
   "metadata": {},
   "outputs": [],
   "source": [
    "val dt: DataFrame = spark.read.schema(schema)\n",
    "    .option(\"multiline\", \"true\")\n",
    "    .option(\"dateFormat\", \"yyyy-MM\")\n",
    "    .json(\"D:/TFGAlvaroSanchez/data2/0201D(Barcelona)-2021.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f606dae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1f4d444",
   "metadata": {},
   "outputs": [],
   "source": [
    "val dt: DataFrame = spark.read\n",
    "    .option(\"multiline\", \"true\")\n",
    "    .json(\"D:/TFGAlvaroSanchez/data2/0201D(Barcelona)-2021.json\")\n",
    "    .select(//$\"fecha\".cast(DateType), \n",
    "            func.to_date($\"fecha\").alias(\"fecha\"),\n",
    "            $\"indicativo\", \n",
    "            $\"p_max\",\n",
    "            $\"glo\".cast(DoubleType), \n",
    "            $\"hr\".cast(DoubleType), \n",
    "            $\"nw_55\".cast(IntegerType), \n",
    "            $\"tm_min\".cast(DoubleType), \n",
    "            $\"ta_max\", \n",
    "            $\"ts_min\".cast(DoubleType), \n",
    "            $\"nt_30\".cast(IntegerType), \n",
    "            $\"n_des\".cast(IntegerType), \n",
    "            $\"w_racha\", \n",
    "            $\"np_100\".cast(IntegerType), \n",
    "            $\"nw_91\".cast(IntegerType), \n",
    "            $\"np_001\".cast(IntegerType), \n",
    "            $\"ta_min\", \n",
    "            $\"w_rec\".cast(IntegerType), \n",
    "            $\"e\".cast(DoubleType), \n",
    "            $\"np_300\".cast(IntegerType), \n",
    "            $\"p_mes\".cast(DoubleType), \n",
    "            $\"w_med\".cast(DoubleType), \n",
    "            $\"nt_00\".cast(IntegerType), \n",
    "            $\"ti_max\".cast(DoubleType), \n",
    "            $\"tm_mes\".cast(DoubleType), \n",
    "            $\"tm_max\".cast(DoubleType), \n",
    "            $\"np_010\".cast(IntegerType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c474860",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f24e02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5991909d",
   "metadata": {},
   "source": [
    "### Temperatura media en españa"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39024119",
   "metadata": {},
   "outputs": [],
   "source": [
    "val data: DataFrame = spark.read\n",
    "    .option(\"multiline\", \"true\")\n",
    "    .json(\"D:/TFGAlvaroSanchez/data2/*.json\")\n",
    "    .select($\"fecha\".cast(DateType), \n",
    "            $\"indicativo\", \n",
    "            $\"p_max\",\n",
    "            $\"glo\".cast(DoubleType), \n",
    "            $\"hr\".cast(DoubleType), \n",
    "            $\"nw_55\".cast(IntegerType), \n",
    "            $\"tm_min\".cast(DoubleType), \n",
    "            $\"ta_max\", \n",
    "            $\"ts_min\".cast(DoubleType), \n",
    "            $\"nt_30\".cast(IntegerType), \n",
    "            $\"n_des\".cast(IntegerType), \n",
    "            $\"w_racha\", \n",
    "            $\"np_100\".cast(IntegerType), \n",
    "            $\"nw_91\".cast(IntegerType), \n",
    "            $\"np_001\".cast(IntegerType), \n",
    "            $\"ta_min\", \n",
    "            $\"w_rec\".cast(IntegerType), \n",
    "            $\"e\".cast(DoubleType), \n",
    "            $\"np_300\".cast(IntegerType), \n",
    "            $\"p_mes\".cast(DoubleType), \n",
    "            $\"w_med\".cast(DoubleType), \n",
    "            $\"nt_00\".cast(IntegerType), \n",
    "            $\"ti_max\".cast(DoubleType), \n",
    "            $\"tm_mes\".cast(DoubleType), \n",
    "            $\"tm_max\".cast(DoubleType), \n",
    "            $\"np_010\".cast(IntegerType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8af696f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.filter($\"fecha\".isNotNull)\n",
    "    .select($\"tm_mes\".alias(\"temperatura media\"))\n",
    "    .describe()\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8dd96364",
   "metadata": {},
   "source": [
    "### Fecha y estaciones con temp >35º (Utilizando expr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "741aece5",
   "metadata": {},
   "outputs": [],
   "source": [
    "val data: DataFrame = spark.read\n",
    "    .option(\"multiline\", \"true\")\n",
    "    .json(\"D:/TFGAlvaroSanchez/data2/*.json\")\n",
    "    .select($\"fecha\".cast(DateType), \n",
    "            $\"indicativo\", \n",
    "            $\"p_max\",\n",
    "            $\"glo\".cast(DoubleType), \n",
    "            $\"hr\".cast(DoubleType), \n",
    "            $\"nw_55\".cast(IntegerType), \n",
    "            $\"tm_min\".cast(DoubleType), \n",
    "            $\"ta_max\", \n",
    "            $\"ts_min\".cast(DoubleType), \n",
    "            $\"nt_30\".cast(IntegerType), \n",
    "            $\"n_des\".cast(IntegerType), \n",
    "            $\"w_racha\", \n",
    "            $\"np_100\".cast(IntegerType), \n",
    "            $\"nw_91\".cast(IntegerType), \n",
    "            $\"np_001\".cast(IntegerType), \n",
    "            $\"ta_min\", \n",
    "            $\"w_rec\".cast(IntegerType), \n",
    "            $\"e\".cast(DoubleType), \n",
    "            $\"np_300\".cast(IntegerType), \n",
    "            $\"p_mes\".cast(DoubleType), \n",
    "            $\"w_med\".cast(DoubleType), \n",
    "            $\"nt_00\".cast(IntegerType), \n",
    "            $\"ti_max\".cast(DoubleType), \n",
    "            $\"tm_mes\".cast(DoubleType), \n",
    "            $\"tm_max\".cast(DoubleType), \n",
    "            $\"np_010\".cast(IntegerType))\n",
    "val dataWithNameStation = data.join(ids, \"indicativo\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c9cfa957",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataWithNameStation.withColumn(\"ta_max\", split($\"ta_max\", \"\\\\(\"))\n",
    "    .withColumn(\"t_max\", $\"ta_max\"(0).cast(IntegerType))\n",
    "    .withColumn(\"dia\", func.substring($\"ta_max\"(1), 0, 2).cast(IntegerType))\n",
    "    .withColumn(\"calor\", func.expr(\"t_max > 35\"))\n",
    "    .filter($\"calor\" && $\"fecha\".isNotNull)\n",
    "    .select($\"ubicacion\", func.year($\"fecha\").alias(\"año\"), func.month($\"fecha\").alias(\"mes\"), $\"dia\")\n",
    "    .show(false)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf201656",
   "metadata": {},
   "source": [
    "### Mostrando graficamente la precipitacion mensual en diferentes estaciones meterologicas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1e29c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "val data2021 = spark.read.option(\"multiline\", \"true\").json(\"D:/TFGAlvaroSanchez/data2/*-2021.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d1ca04c",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2021.write.partitionBy(\"indicativo\").saveAsTable(\"indicativos\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e47e24",
   "metadata": {},
   "source": [
    "### Media de todos los datos, agrupados por fecha y por indicativo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bd72643",
   "metadata": {},
   "outputs": [],
   "source": [
    "val data2021: DataFrame = spark.read\n",
    "    .option(\"multiline\", \"true\")\n",
    "    .json(\"D:/TFGAlvaroSanchez/data2/*-2021.json\")\n",
    "    .select($\"fecha\".cast(DateType), \n",
    "            $\"indicativo\", \n",
    "            $\"p_max\",\n",
    "            $\"glo\".cast(DoubleType), \n",
    "            $\"hr\".cast(DoubleType), \n",
    "            $\"nw_55\".cast(IntegerType), \n",
    "            $\"tm_min\".cast(DoubleType), \n",
    "            $\"ta_max\", \n",
    "            $\"ts_min\".cast(DoubleType), \n",
    "            $\"nt_30\".cast(IntegerType), \n",
    "            $\"n_des\".cast(IntegerType), \n",
    "            $\"w_racha\", \n",
    "            $\"np_100\".cast(IntegerType), \n",
    "            $\"nw_91\".cast(IntegerType), \n",
    "            $\"np_001\".cast(IntegerType), \n",
    "            $\"ta_min\", \n",
    "            $\"w_rec\".cast(IntegerType), \n",
    "            $\"e\".cast(DoubleType), \n",
    "            $\"np_300\".cast(IntegerType), \n",
    "            $\"p_mes\".cast(DoubleType), \n",
    "            $\"w_med\".cast(DoubleType), \n",
    "            $\"nt_00\".cast(IntegerType), \n",
    "            $\"ti_max\".cast(DoubleType), \n",
    "            $\"tm_mes\".cast(DoubleType), \n",
    "            $\"tm_max\".cast(DoubleType), \n",
    "            $\"np_010\".cast(IntegerType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd5ff8f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val pivotedData2021 = data2021.groupBy(func.year($\"fecha\")).pivot(\"indicativo\").avg()\n",
    "pivotedData2021.select(\"year(fecha)\", \"0201D_avg(tm_mes)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "335a3413",
   "metadata": {},
   "source": [
    "### Leer todos los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "810b5be8",
   "metadata": {},
   "outputs": [],
   "source": [
    "val all = spark.read.option(\"multiline\", \"true\").json(\"D:/TFGAlvaroSanchez/data/*.json\").select(\n",
    "            $\"fecha\".cast(DateType), \n",
    "            $\"indicativo\", \n",
    "            $\"p_max\",\n",
    "            $\"glo\".cast(DoubleType), \n",
    "            $\"hr\".cast(DoubleType), \n",
    "            $\"nw_55\".cast(IntegerType), \n",
    "            $\"tm_min\".cast(DoubleType), \n",
    "            $\"ta_max\", \n",
    "            $\"ts_min\".cast(DoubleType), \n",
    "            $\"nt_30\".cast(IntegerType), \n",
    "            $\"n_des\".cast(IntegerType), \n",
    "            $\"w_racha\", \n",
    "            $\"np_100\".cast(IntegerType), \n",
    "            $\"nw_91\".cast(IntegerType), \n",
    "            $\"np_001\".cast(IntegerType), \n",
    "            $\"ta_min\", \n",
    "            $\"w_rec\".cast(IntegerType), \n",
    "            $\"e\".cast(DoubleType), \n",
    "            $\"np_300\".cast(IntegerType), \n",
    "            $\"p_mes\".cast(DoubleType), \n",
    "            $\"w_med\".cast(DoubleType), \n",
    "            $\"nt_00\".cast(IntegerType), \n",
    "            $\"ti_max\".cast(DoubleType), \n",
    "            $\"tm_mes\".cast(DoubleType), \n",
    "            $\"tm_max\".cast(DoubleType), \n",
    "            $\"np_010\".cast(IntegerType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f9fe84e",
   "metadata": {},
   "outputs": [],
   "source": [
    "all.filter($\"indicativo\" === \"2422\").show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9c0a3c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
