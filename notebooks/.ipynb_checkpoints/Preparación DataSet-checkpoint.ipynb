{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3abfa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "import $ivy.`org.apache.spark::spark-sql:2.4.5` \n",
    "import $ivy.`sh.almond::almond-spark:0.4.0`\n",
    "\n",
    "import org.apache.spark.sql.{NotebookSparkSession, SparkSession}\n",
    "import org.apache.spark.sql.{functions => func, _}\n",
    "import org.apache.spark.sql.types._\n",
    "\n",
    "val spark = NotebookSparkSession\n",
    "      .builder()\n",
    "      .config(\"spark.sql.join.preferSortMergeJoin\", false)\n",
    "      .config(\"spark.sql.shuffle.partitions\", 64)\n",
    "      .master(\"local[4]\")\n",
    "      .getOrCreate()\n",
    "\n",
    "import spark.implicits._\n",
    "\n",
    "import org.slf4j.LoggerFactory\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "\n",
    "Logger.getRootLogger().setLevel(Level.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fdad7873",
   "metadata": {},
   "source": [
    "### Tranformacion de JSON multiline a JSON line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b2a6304",
   "metadata": {},
   "source": [
    "Para esto lo que he hecho ha sido ejecutar en el CMD el siguiente comando `FOR %a IN (../data/*.json) DO jq . -c \"%a\" > \"../JSONLine/%a\"` con el que vamos recorriendo la carpeta donde se encuentran los ficheros JSON multiline y los vamos guardando con la transformacion en la carpeta JSONLine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79e66487",
   "metadata": {},
   "source": [
    "### Leer y pasar datos mensuales a Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4111725b",
   "metadata": {},
   "outputs": [],
   "source": [
    "val schema = StructType(\n",
    "    Array(\n",
    "        StructField(\"fecha\", StringType, true), \n",
    "        StructField(\"indicativo\", StringType, true),\n",
    "        StructField(\"nombre\", StringType, true),\n",
    "        StructField(\"provincia\", StringType, true),\n",
    "        StructField(\"altitud\", StringType, true),\n",
    "        StructField(\"tm_mes\", StringType, true),\n",
    "        StructField(\"tm_max\", StringType, true),\n",
    "        StructField(\"tm_min\", StringType, true), \n",
    "        StructField(\"ta_max\", StringType, true),\n",
    "        StructField(\"ta_min\", StringType, true),\n",
    "        StructField(\"ts_min\", StringType, true),\n",
    "        StructField(\"ti_max\", StringType, true),\n",
    "        StructField(\"nt_30\", StringType, true),\n",
    "        StructField(\"nt_00\", StringType, true),\n",
    "        StructField(\"p_mes\", StringType, true),\n",
    "        StructField(\"p_max\", StringType, true),\n",
    "        StructField(\"np_001\", StringType, true),\n",
    "        StructField(\"np_010\", StringType, true),\n",
    "        StructField(\"np_100\", StringType, true),\n",
    "        StructField(\"np_300\", StringType, true),\n",
    "        StructField(\"hr\", StringType, true), \n",
    "        StructField(\"e\", StringType, true),\n",
    "        StructField(\"n_llu\", StringType, true),\n",
    "        StructField(\"n_nie\", StringType, true),\n",
    "        StructField(\"n_gra\", StringType, true),\n",
    "        StructField(\"n_tor\", StringType, true),\n",
    "        StructField(\"n_fog\", StringType, true),\n",
    "        StructField(\"n_des\", StringType, true),\n",
    "        StructField(\"n_nub\", StringType, true),\n",
    "        StructField(\"n_cub\", StringType, true),\n",
    "        StructField(\"inso\", StringType, true),\n",
    "        StructField(\"p_sol\", StringType, true),\n",
    "        StructField(\"glo\", StringType, true),\n",
    "        StructField(\"evap\", StringType, true),\n",
    "        StructField(\"w_rec\", StringType, true),\n",
    "        StructField(\"w_racha\", StringType, true),\n",
    "        StructField(\"nw_55\", StringType, true),\n",
    "        StructField(\"nw_91\", StringType, true),\n",
    "        StructField(\"w_med\", StringType, true),\n",
    "        StructField(\"q_med\", StringType, true),\n",
    "        StructField(\"q_max\", StringType, true),\n",
    "        StructField(\"q_min\", StringType, true),\n",
    "        StructField(\"q_mar\", StringType, true),\n",
    "        StructField(\"ts_10\", StringType, true),\n",
    "        StructField(\"ts_20\", StringType, true),\n",
    "        StructField(\"ts_50\", StringType, true),\n",
    "        StructField(\"nv_0050\", StringType, true),\n",
    "        StructField(\"nv_0100\", StringType, true),\n",
    "        StructField(\"nv_1000\", StringType, true)       \n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9c1d615",
   "metadata": {},
   "outputs": [],
   "source": [
    "val allData = spark.read.schema(schema).json(\"../data/monthJSONLine/*.json\")\n",
    "    .select(\n",
    "            $\"fecha\".cast(DateType), \n",
    "            $\"indicativo\", \n",
    "            $\"p_max\",\n",
    "            $\"glo\".cast(DoubleType), \n",
    "            $\"hr\".cast(DoubleType), \n",
    "            $\"nw_55\".cast(IntegerType), \n",
    "            $\"tm_min\".cast(DoubleType), \n",
    "            $\"ta_max\", \n",
    "            $\"ts_min\".cast(DoubleType), \n",
    "            $\"nt_30\".cast(IntegerType), \n",
    "            $\"n_des\".cast(IntegerType), \n",
    "            $\"w_racha\", \n",
    "            $\"np_100\".cast(IntegerType), \n",
    "            $\"nw_91\".cast(IntegerType), \n",
    "            $\"np_001\".cast(IntegerType), \n",
    "            $\"ta_min\", \n",
    "            $\"w_rec\".cast(IntegerType), \n",
    "            $\"e\".cast(DoubleType), \n",
    "            $\"np_300\".cast(IntegerType), \n",
    "            $\"p_mes\".cast(DoubleType), \n",
    "            $\"w_med\".cast(DoubleType), \n",
    "            $\"nt_00\".cast(IntegerType), \n",
    "            $\"ti_max\".cast(DoubleType), \n",
    "            $\"tm_mes\".cast(DoubleType), \n",
    "            $\"tm_max\".cast(DoubleType), \n",
    "            $\"np_010\".cast(IntegerType)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76d9bd20",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.write.format(\"parquet\").partitionBy(\"indicativo\").mode(\"overwrite\").save(\"../data/monthParquet/\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "635d49d3",
   "metadata": {},
   "source": [
    "### Leer y pasar datos diarios a Parquet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "130eb4f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "val schema = StructType(\n",
    "    Array(\n",
    "        StructField(\"fecha\", StringType, true), \n",
    "        StructField(\"indicativo\", StringType, true),\n",
    "        StructField(\"nombre\", StringType, true),\n",
    "        StructField(\"provincia\", StringType, true),\n",
    "        StructField(\"altitud\", StringType, true),\n",
    "        StructField(\"tmed\", StringType, true),\n",
    "        StructField(\"prec\", StringType, true),\n",
    "        StructField(\"tmin\", StringType, true),\n",
    "        StructField(\"horatmin\", StringType, true),\n",
    "        StructField(\"tmax\", StringType, true),\n",
    "        StructField(\"horatmax\", StringType, true),\n",
    "        StructField(\"dir\", StringType, true),\n",
    "        StructField(\"velmedia\", StringType, true),\n",
    "        StructField(\"racha\", StringType, true),\n",
    "        StructField(\"horaracha\", StringType, true),\n",
    "        StructField(\"sol\", StringType, true),\n",
    "        StructField(\"presMax\", StringType, true),\n",
    "        StructField(\"horaPresMax\", StringType, true),\n",
    "        StructField(\"presMin\", StringType, true),\n",
    "        StructField(\"horaPresMin\", StringType, true)\n",
    "    )\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c698a43",
   "metadata": {},
   "outputs": [],
   "source": [
    "val allData = spark.read.schema(schema).json(\"../data/dayJSONLine/*.json\")\n",
    "    .withColumn(\"fecha\", $\"fecha\".cast(DateType))\n",
    "    .withColumn(\"altitud\", $\"altitud\".cast(IntegerType))\n",
    "    .withColumn(\"tmed\", func.regexp_replace($\"tmed\", \",\", \".\").cast(DoubleType))\n",
    "    .withColumn(\"prec\", func.regexp_replace($\"prec\", \",\", \".\").cast(DoubleType))\n",
    "    .withColumn(\"tmin\", func.regexp_replace($\"tmin\", \",\", \".\").cast(DoubleType))\n",
    "    .withColumn(\"tmax\", func.regexp_replace($\"tmax\", \",\", \".\").cast(DoubleType))\n",
    "    .withColumn(\"dir\", $\"dir\".cast(IntegerType))\n",
    "    .withColumn(\"velmedia\", func.regexp_replace($\"velmedia\", \",\", \".\").cast(DoubleType))\n",
    "    .withColumn(\"racha\", func.regexp_replace($\"racha\", \",\", \".\").cast(DoubleType))\n",
    "    .withColumn(\"sol\", func.regexp_replace($\"sol\", \",\", \".\").cast(DoubleType))\n",
    "    .withColumn(\"presMax\", func.regexp_replace($\"presMax\", \",\", \".\").cast(DoubleType))\n",
    "    .withColumn(\"horaPresMax\", $\"horaPresMax\".cast(IntegerType))\n",
    "    .withColumn(\"presMin\", func.regexp_replace($\"presMin\", \",\", \".\").cast(DoubleType))\n",
    "    .withColumn(\"horaPresMin\", $\"horaPresmin\".cast(IntegerType))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b5fd615",
   "metadata": {},
   "outputs": [],
   "source": [
    "allData.write.format(\"parquet\").partitionBy(\"indicativo\").mode(\"overwrite\").save(\"../data/dayParquet/\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
