{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create the Spark session\n",
    "\n",
    "The Spark session is the entry point to the Spark interpreter. We need it for running Spark programs.\n",
    "\n",
    "\n",
    "###### Para crear una sesion de Spark\n",
    "\n",
    "###### En intelIJ\n",
    "\n",
    "###### val spark = SparkSession.builder.master(\"local[*]\").getOrCreate()\n",
    "\n",
    "###### En build.sbt \n",
    "\n",
    "###### libraryDependencies += \"org.apache.spark\" %% \"spark-sql\" % \"3.3.0\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading spark-stubs\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "log4j:WARN No appenders could be found for logger (org.eclipse.jetty.util.log).\n",
      "log4j:WARN Please initialize the log4j system properly.\n",
      "log4j:WARN See http://logging.apache.org/log4j/1.2/faq.html#noconfig for more info.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating SparkSession\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Spark's default log4j profile: org/apache/spark/log4j-defaults.properties\n",
      "22/07/11 11:34:17 INFO SparkContext: Running Spark version 2.4.5\n",
      "22/07/11 11:34:18 INFO SparkContext: Submitted application: b51e85b2-6942-47ac-b2dc-1eb36f4a0bfd\n",
      "22/07/11 11:34:18 INFO SecurityManager: Changing view acls to: Alvaro\n",
      "22/07/11 11:34:18 INFO SecurityManager: Changing modify acls to: Alvaro\n",
      "22/07/11 11:34:18 INFO SecurityManager: Changing view acls groups to: \n",
      "22/07/11 11:34:18 INFO SecurityManager: Changing modify acls groups to: \n",
      "22/07/11 11:34:18 INFO SecurityManager: SecurityManager: authentication disabled; ui acls disabled; users  with view permissions: Set(Alvaro); groups with view permissions: Set(); users  with modify permissions: Set(Alvaro); groups with modify permissions: Set()\n",
      "22/07/11 11:34:20 INFO Utils: Successfully started service 'sparkDriver' on port 51434.\n",
      "22/07/11 11:34:20 INFO SparkEnv: Registering MapOutputTracker\n",
      "22/07/11 11:34:20 INFO SparkEnv: Registering BlockManagerMaster\n",
      "22/07/11 11:34:20 INFO BlockManagerMasterEndpoint: Using org.apache.spark.storage.DefaultTopologyMapper for getting topology information\n",
      "22/07/11 11:34:20 INFO BlockManagerMasterEndpoint: BlockManagerMasterEndpoint up\n",
      "22/07/11 11:34:20 INFO DiskBlockManager: Created local directory at C:\\Users\\alvar\\AppData\\Local\\Temp\\blockmgr-763008f5-1a0e-4b23-b4da-5071a8f0ae8b\n",
      "22/07/11 11:34:20 INFO MemoryStore: MemoryStore started with capacity 1646.4 MB\n",
      "22/07/11 11:34:20 INFO SparkEnv: Registering OutputCommitCoordinator\n",
      "22/07/11 11:34:20 INFO Utils: Successfully started service 'SparkUI' on port 4042.\n",
      "22/07/11 11:34:20 INFO SparkUI: Bound SparkUI to 0.0.0.0, and started at http://LAPTOP-30N4Q54J.mshome.net:4042\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/jitpack.io/com/github/jupyter/jvm-repr/0.4.0/jvm-repr-0.4.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jvm-repr-0.4.0.jar with timestamp 1657532061017\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/github/javaparser/javaparser-core/3.2.5/javaparser-core-3.2.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/javaparser-core-3.2.5.jar with timestamp 1657532061021\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/github/scopt/scopt_2.12/3.5.0/scopt_2.12-3.5.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/scopt_2.12-3.5.0.jar with timestamp 1657532061023\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/acyclic_2.12/0.1.5/acyclic_2.12-0.1.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/acyclic_2.12-0.1.5.jar with timestamp 1657532061026\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-interp_2.12.8/1.6.5/ammonite-interp_2.12.8-1.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/ammonite-interp_2.12.8-1.6.5.jar with timestamp 1657532061027\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-ops_2.12/1.6.5/ammonite-ops_2.12-1.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/ammonite-ops_2.12-1.6.5.jar with timestamp 1657532061028\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-repl_2.12.8/1.6.5/ammonite-repl_2.12.8-1.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/ammonite-repl_2.12.8-1.6.5.jar with timestamp 1657532061039\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-runtime_2.12/1.6.5/ammonite-runtime_2.12-1.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/ammonite-runtime_2.12-1.6.5.jar with timestamp 1657532061041\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-terminal_2.12/1.6.5/ammonite-terminal_2.12-1.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/ammonite-terminal_2.12-1.6.5.jar with timestamp 1657532061130\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/ammonite-util_2.12/1.6.5/ammonite-util_2.12-1.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/ammonite-util_2.12-1.6.5.jar with timestamp 1657532061146\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/fansi_2.12/0.2.4/fansi_2.12-0.2.4.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/fansi_2.12-0.2.4.jar with timestamp 1657532061154\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/fastparse_2.12/2.1.0/fastparse_2.12-2.1.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/fastparse_2.12-2.1.0.jar with timestamp 1657532061156\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/geny_2.12/0.1.5/geny_2.12-0.1.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/geny_2.12-0.1.5.jar with timestamp 1657532061166\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/os-lib_2.12/0.2.6/os-lib_2.12-0.2.6.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/os-lib_2.12-0.2.6.jar with timestamp 1657532061169\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/pprint_2.12/0.5.2/pprint_2.12-0.5.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/pprint_2.12-0.5.2.jar with timestamp 1657532061170\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/requests_2.12/0.1.7/requests_2.12-0.1.7.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/requests_2.12-0.1.7.jar with timestamp 1657532061171\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/scalaparse_2.12/2.1.0/scalaparse_2.12-2.1.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/scalaparse_2.12-2.1.0.jar with timestamp 1657532061174\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/sourcecode_2.12/0.1.5/sourcecode_2.12-0.1.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/sourcecode_2.12-0.1.5.jar with timestamp 1657532061176\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/ujson_2.12/0.7.1/ujson_2.12-0.7.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/ujson_2.12-0.7.1.jar with timestamp 1657532061179\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/upack_2.12/0.7.1/upack_2.12-0.7.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/upack_2.12-0.7.1.jar with timestamp 1657532061180\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/upickle-core_2.12/0.7.1/upickle-core_2.12-0.7.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/upickle-core_2.12-0.7.1.jar with timestamp 1657532061186\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/upickle-implicits_2.12/0.7.1/upickle-implicits_2.12-0.7.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/upickle-implicits_2.12-0.7.1.jar with timestamp 1657532061190\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/upickle_2.12/0.7.1/upickle_2.12-0.7.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/upickle_2.12-0.7.1.jar with timestamp 1657532061192\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/lihaoyi/utest_2.12/0.6.4/utest_2.12-0.6.4.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/utest_2.12-0.6.4.jar with timestamp 1657532061194\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/get-coursier/coursier-cache_2.12/1.1.0-M13-1/coursier-cache_2.12-1.1.0-M13-1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/coursier-cache_2.12-1.1.0-M13-1.jar with timestamp 1657532061198\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/get-coursier/coursier-core_2.12/1.1.0-M13-1/coursier-core_2.12-1.1.0-M13-1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/coursier-core_2.12-1.1.0-M13-1.jar with timestamp 1657532061200\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/get-coursier/coursier_2.12/1.1.0-M13-1/coursier_2.12-1.1.0-M13-1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/coursier_2.12-1.1.0-M13-1.jar with timestamp 1657532061201\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/net/java/dev/jna/jna/4.2.2/jna-4.2.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jna-4.2.2.jar with timestamp 1657532061211\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.21.0-GA/javassist-3.21.0-GA.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/javassist-3.21.0-GA.jar with timestamp 1657532061216\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/jline/jline-reader/3.6.2/jline-reader-3.6.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jline-reader-3.6.2.jar with timestamp 1657532061217\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/jline/jline-terminal-jna/3.6.2/jline-terminal-jna-3.6.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jline-terminal-jna-3.6.2.jar with timestamp 1657532061219\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/jline/jline-terminal/3.6.2/jline-terminal-3.6.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jline-terminal-3.6.2.jar with timestamp 1657532061222\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/1.1.1/scala-xml_2.12-1.1.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/scala-xml_2.12-1.1.1.jar with timestamp 1657532061225\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scala-sbt/test-interface/1.0/test-interface-1.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/test-interface-1.0.jar with timestamp 1657532061226\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/sh/almond/interpreter-api_2.12/0.4.0/interpreter-api_2.12-0.4.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/interpreter-api_2.12-0.4.0.jar with timestamp 1657532061227\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/sh/almond/jupyter-api_2.12/0.4.0/jupyter-api_2.12-0.4.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jupyter-api_2.12-0.4.0.jar with timestamp 1657532061229\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/sh/almond/scala-kernel-api_2.12.8/0.4.0/scala-kernel-api_2.12.8-0.4.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/scala-kernel-api_2.12.8-0.4.0.jar with timestamp 1657532061231\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/json4s/json4s-core_2.12/3.5.3/json4s-core_2.12-3.5.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/json4s-core_2.12-3.5.3.jar with timestamp 1657532061232\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/xml-apis/xml-apis/1.3.04/xml-apis-1.3.04.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/xml-apis-1.3.04.jar with timestamp 1657532061234\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/javax/servlet/javax.servlet-api/3.1.0/javax.servlet-api-3.1.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/javax.servlet-api-3.1.0.jar with timestamp 1657532061235\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-core/3.1.5/metrics-core-3.1.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/metrics-core-3.1.5.jar with timestamp 1657532061237\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/google/inject/guice/3.0/guice-3.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/guice-3.0.jar with timestamp 1657532061238\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-log4j12/1.7.16/slf4j-log4j12-1.7.16.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/slf4j-log4j12-1.7.16.jar with timestamp 1657532061240\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-crypto/1.0.0/commons-crypto-1.0.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-crypto-1.0.0.jar with timestamp 1657532061241\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/xbean/xbean-asm6-shaded/4.8/xbean-asm6-shaded-4.8.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/xbean-asm6-shaded-4.8.jar with timestamp 1657532061242\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/xerces/xercesImpl/2.9.1/xercesImpl-2.9.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/xercesImpl-2.9.1.jar with timestamp 1657532061243\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/github/luben/zstd-jni/1.3.2-2/zstd-jni-1.3.2-2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/zstd-jni-1.3.2-2.jar with timestamp 1657532061244\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/codehaus/jettison/jettison/1.1/jettison-1.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jettison-1.1.jar with timestamp 1657532061245\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-unsafe_2.12/2.4.5/spark-unsafe_2.12-2.4.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-unsafe_2.12-2.4.5.jar with timestamp 1657532061246\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-nodemanager/2.6.5/hadoop-yarn-server-nodemanager-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-yarn-server-nodemanager-2.6.5.jar with timestamp 1657532061247\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-hadoop/1.10.1/parquet-hadoop-1.10.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/parquet-hadoop-1.10.1.jar with timestamp 1657532061248\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/joda-time/joda-time/2.9.9/joda-time-2.9.9.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/joda-time-2.9.9.jar with timestamp 1657532061249\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/commons-io/commons-io/2.4/commons-io-2.4.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-io-2.4.jar with timestamp 1657532061250\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/commons-configuration/commons-configuration/1.6/commons-configuration-1.6.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-configuration-1.6.jar with timestamp 1657532061251\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/antlr/antlr4-runtime/4.7/antlr4-runtime-4.7.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/antlr4-runtime-4.7.jar with timestamp 1657532061252\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-common/2.22.2/jersey-common-2.22.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jersey-common-2.22.2.jar with timestamp 1657532061254\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/airlift/aircompressor/0.10/aircompressor-0.10.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/aircompressor-0.10.jar with timestamp 1657532061260\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-compress/1.8.1/commons-compress-1.8.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-compress-1.8.1.jar with timestamp 1657532061266\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/slf4j/jcl-over-slf4j/1.7.16/jcl-over-slf4j-1.7.16.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jcl-over-slf4j-1.7.16.jar with timestamp 1657532061268\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/javassist/javassist/3.18.1-GA/javassist-3.18.1-GA.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/javassist-3.18.1-GA.jar with timestamp 1657532061270\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/external/aopalliance-repackaged/2.4.0-b34/aopalliance-repackaged-2.4.0-b34.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/aopalliance-repackaged-2.4.0-b34.jar with timestamp 1657532061271\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/lz4/lz4-java/1.4.0/lz4-java-1.4.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/lz4-java-1.4.0.jar with timestamp 1657532061273\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/netty/netty/3.9.9.Final/netty-3.9.9.Final.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/netty-3.9.9.Final.jar with timestamp 1657532061275\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-common_2.12/2.4.5/spark-network-common_2.12-2.4.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-network-common_2.12-2.4.5.jar with timestamp 1657532061278\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/aopalliance/aopalliance/1.0/aopalliance-1.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/aopalliance-1.0.jar with timestamp 1657532061282\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-core/2.7.9/jackson-core-2.7.9.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jackson-core-2.7.9.jar with timestamp 1657532061283\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sql_2.12/2.4.5/spark-sql_2.12-2.4.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-sql_2.12-2.4.5.jar with timestamp 1657532061286\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/google/code/gson/gson/2.2.4/gson-2.2.4.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/gson-2.2.4.jar with timestamp 1657532061290\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/directory/api/api-util/1.0.0-M20/api-util-1.0.0-M20.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/api-util-1.0.0-M20.jar with timestamp 1657532061292\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-client/2.6.5/hadoop-yarn-client-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-yarn-client-2.6.5.jar with timestamp 1657532061294\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/javax/xml/bind/jaxb-api/2.2.2/jaxb-api-2.2.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jaxb-api-2.2.2.jar with timestamp 1657532061295\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-tags_2.12/2.4.5/spark-tags_2.12-2.4.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-tags_2.12-2.4.5.jar with timestamp 1657532061296\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-jackson/1.10.1/parquet-jackson-1.10.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/parquet-jackson-1.10.1.jar with timestamp 1657532061297\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/roaringbitmap/shims/0.7.45/shims-0.7.45.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/shims-0.7.45.jar with timestamp 1657532061299\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/thoughtworks/paranamer/paranamer/2.8/paranamer-2.8.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/paranamer-2.8.jar with timestamp 1657532061301\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/avro/avro/1.8.2/avro-1.8.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/avro-1.8.2.jar with timestamp 1657532061302\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/httpcomponents/httpcore/4.2.4/httpcore-4.2.4.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/httpcore-4.2.4.jar with timestamp 1657532061304\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/carrotsearch/hppc/0.7.2/hppc-0.7.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hppc-0.7.2.jar with timestamp 1657532061306\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-databind/2.6.7.3/jackson-databind-2.6.7.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jackson-databind-2.6.7.3.jar with timestamp 1657532061312\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-kvstore_2.12/2.4.5/spark-kvstore_2.12-2.4.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-kvstore_2.12-2.4.5.jar with timestamp 1657532061315\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/commons-codec/commons-codec/1.10/commons-codec-1.10.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-codec-1.10.jar with timestamp 1657532061318\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/mortbay/jetty/jetty-util/6.1.26/jetty-util-6.1.26.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jetty-util-6.1.26.jar with timestamp 1657532061319\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-common/2.6.5/hadoop-yarn-common-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-yarn-common-2.6.5.jar with timestamp 1657532061321\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/json4s/json4s-scalap_2.12/3.5.3/json4s-scalap_2.12-3.5.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/json4s-scalap_2.12-3.5.3.jar with timestamp 1657532061322\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/commons-beanutils/commons-beanutils/1.7.0/commons-beanutils-1.7.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-beanutils-1.7.0.jar with timestamp 1657532061326\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-ipc/1.8.2/avro-ipc-1.8.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/avro-ipc-1.8.2.jar with timestamp 1657532061327\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-auth/2.6.5/hadoop-auth-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-auth-2.6.5.jar with timestamp 1657532061330\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-vector/0.10.0/arrow-vector-0.10.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/arrow-vector-0.10.0.jar with timestamp 1657532061332\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-common/1.10.1/parquet-common-1.10.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/parquet-common-1.10.1.jar with timestamp 1657532061334\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/ning/compress-lzf/1.0.3/compress-lzf-1.0.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/compress-lzf-1.0.3.jar with timestamp 1657532061335\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/log4j/log4j/1.2.17/log4j-1.2.17.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/log4j-1.2.17.jar with timestamp 1657532061336\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/clearspring/analytics/stream/2.7.0/stream-2.7.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/stream-2.7.0.jar with timestamp 1657532061337\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/vlkan/flatbuffers/1.2.0-3f79e055/flatbuffers-1.2.0-3f79e055.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/flatbuffers-1.2.0-3f79e055.jar with timestamp 1657532061338\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/directory/server/apacheds-i18n/2.0.0-M15/apacheds-i18n-2.0.0-M15.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/apacheds-i18n-2.0.0-M15.jar with timestamp 1657532061339\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/javax/activation/activation/1.1.1/activation-1.1.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/activation-1.1.1.jar with timestamp 1657532061340\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/javax/inject/javax.inject/1/javax.inject-1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/javax.inject-1.jar with timestamp 1657532061341\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/slf4j/jul-to-slf4j/1.7.16/jul-to-slf4j-1.7.16.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jul-to-slf4j-1.7.16.jar with timestamp 1657532061342\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/esotericsoftware/minlog/1.3.0/minlog-1.3.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/minlog-1.3.0.jar with timestamp 1657532061344\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/xmlenc/xmlenc/0.52/xmlenc-0.52.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/xmlenc-0.52.jar with timestamp 1657532061345\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/univocity/univocity-parsers/2.7.3/univocity-parsers-2.7.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/univocity-parsers-2.7.3.jar with timestamp 1657532061346\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/codehaus/janino/janino/3.0.9/janino-3.0.9.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/janino-3.0.9.jar with timestamp 1657532061347\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-core_2.12/2.4.5/spark-core_2.12-2.4.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-core_2.12-2.4.5.jar with timestamp 1657532061349\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/commons-lang/commons-lang/2.6/commons-lang-2.6.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-lang-2.6.jar with timestamp 1657532061350\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/slf4j/slf4j-api/1.7.25/slf4j-api-1.7.25.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/slf4j-api-1.7.25.jar with timestamp 1657532061351\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/oro/oro/2.0.8/oro-2.0.8.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/oro-2.0.8.jar with timestamp 1657532061353\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/javax/annotation/javax.annotation-api/1.2/javax.annotation-api-1.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/javax.annotation-api-1.2.jar with timestamp 1657532061355\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/commons-cli/commons-cli/1.2/commons-cli-1.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-cli-1.2.jar with timestamp 1657532061356\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-math3/3.4.1/commons-math3-3.4.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-math3-3.4.1.jar with timestamp 1657532061357\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-core-asl/1.9.13/jackson-core-asl-1.9.13.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jackson-core-asl-1.9.13.jar with timestamp 1657532061358\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-core/1.5.5/orc-core-1.5.5-nohive.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/orc-core-1.5.5-nohive.jar with timestamp 1657532061359\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/google/guava/guava/16.0.1/guava-16.0.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/guava-16.0.1.jar with timestamp 1657532061360\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-server-common/2.6.5/hadoop-yarn-server-common-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-yarn-server-common-2.6.5.jar with timestamp 1657532061362\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-api/2.4.0-b34/hk2-api-2.4.0-b34.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hk2-api-2.4.0-b34.jar with timestamp 1657532061364\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/fusesource/leveldbjni/leveldbjni-all/1.8/leveldbjni-all-1.8.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/leveldbjni-all-1.8.jar with timestamp 1657532061365\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/osgi-resource-locator/1.0.1/osgi-resource-locator-1.0.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/osgi-resource-locator-1.0.1.jar with timestamp 1657532061366\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-parser-combinators_2.12/1.1.0/scala-parser-combinators_2.12-1.1.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/scala-parser-combinators_2.12-1.1.0.jar with timestamp 1657532061367\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-catalyst_2.12/2.4.5/spark-catalyst_2.12-2.4.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-catalyst_2.12-2.4.5.jar with timestamp 1657532061368\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-yarn-api/2.6.5/hadoop-yarn-api-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-yarn-api-2.6.5.jar with timestamp 1657532061369\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/commons/commons-lang3/3.5/commons-lang3-3.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-lang3-3.5.jar with timestamp 1657532061370\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/commons-collections/commons-collections/3.2.2/commons-collections-3.2.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-collections-3.2.2.jar with timestamp 1657532061371\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-utils/2.4.0-b34/hk2-utils-2.4.0-b34.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hk2-utils-2.4.0-b34.jar with timestamp 1657532061373\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/tukaani/xz/1.5/xz-1.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/xz-1.5.jar with timestamp 1657532061374\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-common/2.6.5/hadoop-common-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-common-2.6.5.jar with timestamp 1657532061375\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-core/2.6.5/hadoop-mapreduce-client-core-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-mapreduce-client-core-2.6.5.jar with timestamp 1657532061377\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/jline/jline/0.9.94/jline-0.9.94.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jline-0.9.94.jar with timestamp 1657532061378\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-mapreduce/1.5.5/orc-mapreduce-1.5.5-nohive.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/orc-mapreduce-1.5.5-nohive.jar with timestamp 1657532061380\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/httpcomponents/httpclient/4.2.5/httpclient-4.2.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/httpclient-4.2.5.jar with timestamp 1657532061382\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-annotations/2.6.5/hadoop-annotations-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-annotations-2.6.5.jar with timestamp 1657532061385\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/spark-project/spark/unused/1.0.0/unused-1.0.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/unused-1.0.0.jar with timestamp 1657532061387\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet-core/2.22.2/jersey-container-servlet-core-2.22.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jersey-container-servlet-core-2.22.2.jar with timestamp 1657532061392\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/codehaus/janino/commons-compiler/3.0.9/commons-compiler-3.0.9.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-compiler-3.0.9.jar with timestamp 1657532061394\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/hk2-locator/2.4.0-b34/hk2-locator-2.4.0-b34.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hk2-locator-2.4.0-b34.jar with timestamp 1657532061394\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-mapper-asl/1.9.13/jackson-mapper-asl-1.9.13.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jackson-mapper-asl-1.9.13.jar with timestamp 1657532061395\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/net/sf/py4j/py4j/0.10.7/py4j-0.10.7.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/py4j-0.10.7.jar with timestamp 1657532061396\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-recipes/2.6.0/curator-recipes-2.6.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/curator-recipes-2.6.0.jar with timestamp 1657532061397\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/google/code/findbugs/jsr305/3.0.2/jsr305-3.0.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jsr305-3.0.2.jar with timestamp 1657532061414\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/orc/orc-shims/1.5.5/orc-shims-1.5.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/orc-shims-1.5.5.jar with timestamp 1657532061415\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-client/2.6.0/curator-client-2.6.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/curator-client-2.6.0.jar with timestamp 1657532061416\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/xerial/snappy/snappy-java/1.1.7.3/snappy-java-1.1.7.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/snappy-java-1.1.7.3.jar with timestamp 1657532061417\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/javax/validation/validation-api/1.1.0.Final/validation-api-1.1.0.Final.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/validation-api-1.1.0.Final.jar with timestamp 1657532061418\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-hdfs/2.6.5/hadoop-hdfs-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-hdfs-2.6.5.jar with timestamp 1657532061419\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/ivy/ivy/2.4.0/ivy-2.4.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/ivy-2.4.0.jar with timestamp 1657532061420\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/javax/xml/stream/stax-api/1.0-2/stax-api-1.0-2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/stax-api-1.0-2.jar with timestamp 1657532061420\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/roaringbitmap/RoaringBitmap/0.7.45/RoaringBitmap-0.7.45.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/RoaringBitmap-0.7.45.jar with timestamp 1657532061422\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-jaxrs/1.9.13/jackson-jaxrs-1.9.13.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jackson-jaxrs-1.9.13.jar with timestamp 1657532061425\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-json/3.1.5/metrics-json-3.1.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/metrics-json-3.1.5.jar with timestamp 1657532061427\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/containers/jersey-container-servlet/2.22.2/jersey-container-servlet-2.22.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jersey-container-servlet-2.22.2.jar with timestamp 1657532061428\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/codehaus/jackson/jackson-xc/1.9.13/jackson-xc-1.9.13.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jackson-xc-1.9.13.jar with timestamp 1657532061428\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/javax/ws/rs/javax.ws.rs-api/2.0.1/javax.ws.rs-api-2.0.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/javax.ws.rs-api-2.0.1.jar with timestamp 1657532061429\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-scala_2.12/2.6.7.1/jackson-module-scala_2.12-2.6.7.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jackson-module-scala_2.12-2.6.7.1.jar with timestamp 1657532061430\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-column/1.10.1/parquet-column-1.10.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/parquet-column-1.10.1.jar with timestamp 1657532061431\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/esotericsoftware/kryo-shaded/4.0.2/kryo-shaded-4.0.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/kryo-shaded-4.0.2.jar with timestamp 1657532061432\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/directory/api/api-asn1-api/1.0.0-M20/api-asn1-api-1.0.0-M20.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/api-asn1-api-1.0.0-M20.jar with timestamp 1657532061434\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/net/razorvine/pyrolite/4.13/pyrolite-4.13.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/pyrolite-4.13.jar with timestamp 1657532061434\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-format/2.4.0/parquet-format-2.4.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/parquet-format-2.4.0.jar with timestamp 1657532061436\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/scala-lang/modules/scala-xml_2.12/1.0.6/scala-xml_2.12-1.0.6.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/scala-xml_2.12-1.0.6.jar with timestamp 1657532061437\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/zookeeper/zookeeper/3.4.6/zookeeper-3.4.6.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/zookeeper-3.4.6.jar with timestamp 1657532061438\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/objenesis/objenesis/2.5.1/objenesis-2.5.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/objenesis-2.5.1.jar with timestamp 1657532061439\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/media/jersey-media-jaxb/2.22.2/jersey-media-jaxb-2.22.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jersey-media-jaxb-2.22.2.jar with timestamp 1657532061440\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/commons-httpclient/commons-httpclient/3.1/commons-httpclient-3.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-httpclient-3.1.jar with timestamp 1657532061445\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-jobclient/2.6.5/hadoop-mapreduce-client-jobclient-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-mapreduce-client-jobclient-2.6.5.jar with timestamp 1657532061446\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/netty/netty-all/4.1.42.Final/netty-all-4.1.42.Final.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/netty-all-4.1.42.Final.jar with timestamp 1657532061448\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-network-shuffle_2.12/2.4.5/spark-network-shuffle_2.12-2.4.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-network-shuffle_2.12-2.4.5.jar with timestamp 1657532061449\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-sketch_2.12/2.4.5/spark-sketch_2.12-2.4.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-sketch_2.12-2.4.5.jar with timestamp 1657532061452\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/twitter/chill-java/0.9.3/chill-java-0.9.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/chill-java-0.9.3.jar with timestamp 1657532061454\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/json4s/json4s-ast_2.12/3.5.3/json4s-ast_2.12-3.5.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/json4s-ast_2.12-3.5.3.jar with timestamp 1657532061457\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/avro/avro-mapred/1.8.2/avro-mapred-1.8.2-hadoop2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/avro-mapred-1.8.2-hadoop2.jar with timestamp 1657532061458\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/parquet/parquet-encoding/1.10.1/parquet-encoding-1.10.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/parquet-encoding-1.10.1.jar with timestamp 1657532061460\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/commons-net/commons-net/3.1/commons-net-3.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-net-3.1.jar with timestamp 1657532061462\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-jvm/3.1.5/metrics-jvm-3.1.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/metrics-jvm-3.1.5.jar with timestamp 1657532061464\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-client/2.22.2/jersey-client-2.22.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jersey-client-2.22.2.jar with timestamp 1657532061465\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-memory/0.10.0/arrow-memory-0.10.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/arrow-memory-0.10.0.jar with timestamp 1657532061467\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-shuffle/2.6.5/hadoop-mapreduce-client-shuffle-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-mapreduce-client-shuffle-2.6.5.jar with timestamp 1657532061468\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/module/jackson-module-paranamer/2.7.9/jackson-module-paranamer-2.7.9.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jackson-module-paranamer-2.7.9.jar with timestamp 1657532061471\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-app/2.6.5/hadoop-mapreduce-client-app-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-mapreduce-client-app-2.6.5.jar with timestamp 1657532061477\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/htrace/htrace-core/3.0.4/htrace-core-3.0.4.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/htrace-core-3.0.4.jar with timestamp 1657532061507\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/bundles/repackaged/jersey-guava/2.22.2/jersey-guava-2.22.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jersey-guava-2.22.2.jar with timestamp 1657532061509\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/commons-digester/commons-digester/1.8/commons-digester-1.8.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/commons-digester-1.8.jar with timestamp 1657532061516\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/spark/spark-launcher_2.12/2.4.5/spark-launcher_2.12-2.4.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-launcher_2.12-2.4.5.jar with timestamp 1657532061518\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/twitter/chill_2.12/0.9.3/chill_2.12-0.9.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/chill_2.12-0.9.3.jar with timestamp 1657532061519\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/arrow/arrow-format/0.10.0/arrow-format-0.10.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/arrow-format-0.10.0.jar with timestamp 1657532061526\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/google/protobuf/protobuf-java/2.5.0/protobuf-java-2.5.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/protobuf-java-2.5.0.jar with timestamp 1657532061529\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/directory/server/apacheds-kerberos-codec/2.0.0-M15/apacheds-kerberos-codec-2.0.0-M15.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/apacheds-kerberos-codec-2.0.0-M15.jar with timestamp 1657532061534\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-client/2.6.5/hadoop-client-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-client-2.6.5.jar with timestamp 1657532061563\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/dropwizard/metrics/metrics-graphite/3.1.5/metrics-graphite-3.1.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/metrics-graphite-3.1.5.jar with timestamp 1657532061564\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/json4s/json4s-jackson_2.12/3.5.3/json4s-jackson_2.12-3.5.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/json4s-jackson_2.12-3.5.3.jar with timestamp 1657532061565\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/hk2/external/javax.inject/2.4.0-b34/javax.inject-2.4.0-b34.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/javax.inject-2.4.0-b34.jar with timestamp 1657532061566\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/glassfish/jersey/core/jersey-server/2.22.2/jersey-server-2.22.2.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jersey-server-2.22.2.jar with timestamp 1657532061567\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/fasterxml/jackson/core/jackson-annotations/2.6.7/jackson-annotations-2.6.7.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jackson-annotations-2.6.7.jar with timestamp 1657532061568\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/hadoop/hadoop-mapreduce-client-common/2.6.5/hadoop-mapreduce-client-common-2.6.5.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/hadoop-mapreduce-client-common-2.6.5.jar with timestamp 1657532061568\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/apache/curator/curator-framework/2.6.0/curator-framework-2.6.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/curator-framework-2.6.0.jar with timestamp 1657532061569\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/sh/almond/almond-spark_2.12/0.4.0/almond-spark_2.12-0.4.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/almond-spark_2.12-0.4.0.jar with timestamp 1657532061570\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/io/argonaut/argonaut_2.12/6.2.3/argonaut_2.12-6.2.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/argonaut_2.12-6.2.3.jar with timestamp 1657532061571\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-server/9.4.15.v20190215/jetty-server-9.4.15.v20190215.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jetty-server-9.4.15.v20190215.jar with timestamp 1657532061576\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/sh/almond/ammonite-spark_2.12/0.4.0/ammonite-spark_2.12-0.4.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/ammonite-spark_2.12-0.4.0.jar with timestamp 1657532061590\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/github/alexarchambault/argonaut-shapeless_6.2_2.12/1.2.0-M10/argonaut-shapeless_6.2_2.12-1.2.0-M10.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/argonaut-shapeless_6.2_2.12-1.2.0-M10.jar with timestamp 1657532061594\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-io/9.4.15.v20190215/jetty-io-9.4.15.v20190215.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jetty-io-9.4.15.v20190215.jar with timestamp 1657532061596\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/typelevel/macro-compat_2.12/1.1.1/macro-compat_2.12-1.1.1.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/macro-compat_2.12-1.1.1.jar with timestamp 1657532061597\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-http/9.4.15.v20190215/jetty-http-9.4.15.v20190215.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jetty-http-9.4.15.v20190215.jar with timestamp 1657532061599\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/org/eclipse/jetty/jetty-util/9.4.15.v20190215/jetty-util-9.4.15.v20190215.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/jetty-util-9.4.15.v20190215.jar with timestamp 1657532061600\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/com/chuusai/shapeless_2.12/2.3.3/shapeless_2.12-2.3.3.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/shapeless_2.12-2.3.3.jar with timestamp 1657532061600\n",
      "22/07/11 11:34:21 INFO SparkContext: Added JAR file:/C:/Users/alvar/AppData/Local/Coursier/cache/v1/https/repo1.maven.org/maven2/sh/almond/spark-stubs_24_2.12/0.4.0/spark-stubs_24_2.12-0.4.0.jar at spark://LAPTOP-30N4Q54J.mshome.net:51434/jars/spark-stubs_24_2.12-0.4.0.jar with timestamp 1657532061601\n",
      "22/07/11 11:34:22 INFO Executor: Starting executor ID driver on host localhost\n",
      "22/07/11 11:34:22 INFO Executor: Using REPL class URI: http://172.30.32.1:51391\n",
      "22/07/11 11:34:22 INFO Utils: Successfully started service 'org.apache.spark.network.netty.NettyBlockTransferService' on port 51477.\n",
      "22/07/11 11:34:22 INFO NettyBlockTransferService: Server created on LAPTOP-30N4Q54J.mshome.net:51477\n",
      "22/07/11 11:34:22 INFO BlockManager: Using org.apache.spark.storage.RandomBlockReplicationPolicy for block replication policy\n",
      "22/07/11 11:34:22 INFO BlockManagerMaster: Registering BlockManager BlockManagerId(driver, LAPTOP-30N4Q54J.mshome.net, 51477, None)\n",
      "22/07/11 11:34:22 INFO BlockManagerMasterEndpoint: Registering block manager LAPTOP-30N4Q54J.mshome.net:51477 with 1646.4 MB RAM, BlockManagerId(driver, LAPTOP-30N4Q54J.mshome.net, 51477, None)\n",
      "22/07/11 11:34:22 INFO BlockManagerMaster: Registered BlockManager BlockManagerId(driver, LAPTOP-30N4Q54J.mshome.net, 51477, None)\n",
      "22/07/11 11:34:22 INFO BlockManager: Initialized BlockManager: BlockManagerId(driver, LAPTOP-30N4Q54J.mshome.net, 51477, None)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<a href=\"http://LAPTOP-30N4Q54J.mshome.net:4042\">Spark UI</a>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                                   \n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36m$ivy.$                              \n",
       "\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{NotebookSparkSession, SparkSession}\n",
       "\n",
       "\u001b[39m\r\n",
       "\u001b[36mspark\u001b[39m: \u001b[32mSparkSession\u001b[39m = org.apache.spark.sql.SparkSession@4be13f45"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "// Create a Spark session in standalone mode\n",
    "\n",
    "import $ivy.`org.apache.spark::spark-sql:2.4.5` \n",
    "import $ivy.`sh.almond::almond-spark:0.4.0`\n",
    "\n",
    "import org.apache.spark.sql.{NotebookSparkSession, SparkSession}\n",
    "\n",
    "val spark: SparkSession = \n",
    "    NotebookSparkSession\n",
    "      .builder()\n",
    "      .master(\"local[*]\")\n",
    "      .getOrCreate()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logging configuration\n",
    "\n",
    "This is convenient to minimize the amount of info displayed in the terminal."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Para minimizar la cantidad de informacion del terminal, solo nos mostrara los errores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36morg.slf4j.LoggerFactory\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.log4j.{Level, Logger}\n",
       "\u001b[39m"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import org.slf4j.LoggerFactory\n",
    "import org.apache.log4j.{Level, Logger}\n",
    "Logger.getRootLogger().setLevel(Level.ERROR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Useful imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[32mimport \u001b[39m\u001b[36mspark.implicits._\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.{functions => func, _}\n",
       "\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36morg.apache.spark.sql.types._\u001b[39m"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spark.implicits._\n",
    "import org.apache.spark.sql.{functions => func, _}\n",
    "import org.apache.spark.sql.types._"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Para transformar en un dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres3\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List(1,2,3,4).toDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# First difference: performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define a heavy computation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mheavyComp\u001b[39m"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def heavyComp(ms: Int = 1000)(x: Int): Int = {\n",
    "  Thread.sleep(ms)\n",
    "  x+1\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and a way to measure execution time:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mfunction\u001b[39m \u001b[36mrun\u001b[39m"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def run[A](code: => A): A = {\n",
    "    val start = System.currentTimeMillis()\n",
    "    val res = code\n",
    "    println(s\"Took ${System.currentTimeMillis() - start}\")\n",
    "    res\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The following Scala Collection program takes some time to execute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4038\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres6\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m14\u001b[39m"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run{\n",
    "    List(1,2,3,4).map(heavyComp(): Int => Int).reduce(_ + _)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, the equivalent Dataset program takes half time (or less time depending on the number of cores of your processor)!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<script>\n",
       "var comm = Jupyter.notebook.kernel.comm_manager.new_comm('cancel-stage-029ddc24-f0e6-4b96-96ab-447dd1159a74', {});\n",
       "\n",
       "function cancelStage(stageId) {\n",
       "  console.log('Cancelling stage ' + stageId);\n",
       "  comm.send({ 'stageId': stageId });\n",
       "}\n",
       "</script>\n",
       "          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">reduce at cmd7.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 25436\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres7\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m14\u001b[39m"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(\n",
    "    List(1,2,3,4).toDS.map(heavyComp()).reduce(_ + _)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Dataset program run faster because the Spark framework is designed to take advantage of the parallel and distributed architecture of your computing infrastructure. In our case, it simply exploits the number of cores of your processor.\n",
    "\n",
    "\n",
    "###### El programa Dataset se ejecuta ms rpido porque el marco Spark est diseado para aprovechar la arquitectura paralela y distribuida de su infraestructura informtica. En nuestro caso, simplemente explota la cantidad de ncleos de su procesador"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Third difference: the execution framework"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When an action is applied on a `Dataset` program a _job_ is executed by the distributed platform of Spark through a sequence of *stages*; in each stage, the work to be done is performed concurrently by a number of _tasks_. \n",
    "\n",
    "The so-called [Spark UI](http://localhost:4040/) allows us to debug the execution process of all the jobs that are submitted for execution through a given Spark session. For instace, the following action launches a job that can be inspected through the Spark UI: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mds\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ds: Dataset[Int] = List(1,2,3,4).toDS.map(heavyComp())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) SerializeFromObject [input[0, int, false] AS value#18]\n",
      "+- *(1) MapElements ammonite.$sess.cmd8$Helper$$Lambda$4141/0x0000000801631840@490a6106, obj#17: int\n",
      "   +- *(1) DeserializeToObject value#13: int, obj#16: int\n",
      "      +- LocalTableScan [value#13]\n"
     ]
    }
   ],
   "source": [
    "ds.explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd10.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres10\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each bar in the notebook execution corresponds to one stage of the job exectuion; the X/Y label in each bar indicates the number of tasks already executed (X) and the total number of tasks of that stage (Y). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the work performed by tasks in each partition through `foreachPartition`:\n",
    "\n",
    "###### Para obtener el trabajo realizado en cada particion `foreachPartition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd11.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Task output: List(3)\n",
      "Task output: List(5)\n",
      "Task output: List(2)\n",
      "Task output: List(4)\n"
     ]
    }
   ],
   "source": [
    "ds.foreachPartition{ it : Iterator[Int] => \n",
    "    println(s\"Task output: \" + it.toList)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mclass\u001b[39m \u001b[36mDatasetOps\u001b[39m"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "implicit class DatasetOps[T](ds: Dataset[T]){\n",
    "    def collectPartitions: Unit = \n",
    "        ds.foreachPartition{it : Iterator[T] => println(it.toList)}\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of tasks scheduled for each stage depends on the number of partitions associated to the dataset. When the dataset is first created from a Scala collection, the number of partitions defaults to the number of cores specified when the Spark context was created. \n",
    "\n",
    "###### Para ver el numero de particiones usamos `.getNumPartitions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres13\u001b[39m: \u001b[32mInt\u001b[39m = \u001b[32m4\u001b[39m"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List(1,2,3,4).toDS.rdd.getNumPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of partitions can be set to a specific value using `repartition`: \n",
    "\n",
    "###### Para establecer el numero de particiones `repartition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd12.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd12.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    24 / 24\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List(4)\n",
      "List(9)\n",
      "List(13)\n",
      "List(7)\n",
      "List(3)\n",
      "List(11)\n",
      "List(5, 12)\n",
      "List(2, 10)\n",
      "List(6, 8)\n"
     ]
    }
   ],
   "source": [
    "List(1,2,3,4,5,6,7,8,9,10,11,12).toDS\n",
    "    .repartition(24)\n",
    "    .map(heavyComp(2000))\n",
    "    .collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Shuffling: narrow vs. wide transformations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that a new stage is created when the dataset is repartitioned. More commonly, new stages are created when so-called _wide_ transformations are interpreted. _Narrow_ transformations are those transformations which are not wide: `map`, `filter`, etc. For instance, this program will execute in one stage: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd27.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    5 / 5\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres27\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)] = \u001b[33mArray\u001b[39m(\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m2\u001b[39m),\n",
       "  (\u001b[32m\"b\"\u001b[39m, \u001b[32m3\u001b[39m),\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[32m4\u001b[39m),\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[32m4\u001b[39m),\n",
       "  (\u001b[32m\"b\"\u001b[39m, \u001b[32m5\u001b[39m)\n",
       ")"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List((\"a\", 1), (\"b\", 2), (\"a\", 3), (\"d\", 3), (\"b\", 4)).toDS\n",
    "    .map{ case (key, value) => (key, value + 1) }\n",
    "    .collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and the following one as well:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd28.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    5 / 5\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres28\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mInt\u001b[39m)] = \u001b[33mArray\u001b[39m((\u001b[32m\"a\"\u001b[39m, \u001b[32m2\u001b[39m), (\u001b[32m\"a\"\u001b[39m, \u001b[32m4\u001b[39m))"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List((\"a\", 1), (\"b\", 2), (\"a\", 3), (\"d\", 3), (\"b\", 4)).toDS\n",
    "    .map{ case (key, value) => (key, value + 1) }\n",
    "    .filter{ t => t._1 == \"a\" }\n",
    "    .collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "However, this one introduces a new stage:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd29.sc:4</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    5 / 5\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd29.sc:4</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    200 / 200\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres29\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mList\u001b[39m[\u001b[32mInt\u001b[39m])] = \u001b[33mArray\u001b[39m(\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[33mList\u001b[39m(\u001b[32m4\u001b[39m)),\n",
       "  (\u001b[32m\"b\"\u001b[39m, \u001b[33mList\u001b[39m(\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m)),\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[33mList\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m))\n",
       ")"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List((\"a\", 1), (\"b\", 2), (\"a\", 3), (\"d\", 3), (\"b\", 4)).toDS\n",
    "    .map{ case (key, value) => (key, value + 1) }\n",
    "    .groupByKey(_._1)\n",
    "    .mapGroups((key, values) => (key, values.toList.map(_._2)))\n",
    "    .collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why? Which difference between `filter` and `groupBy` creates such a need for a new stage? And why the next stage generates a dataset with 200 partitions? Let's answer these questions: \n",
    "* First, a new stage is created when data needs to be moved, or *shuffled*, between partitions. \n",
    "* Indeed, this is the case for `groupBy`.\n",
    "* Last, 200 is the default number of partitions created when a shuffled is needed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This value can be customised as follows:\n",
    "\n",
    "###### Para establecer el numero de particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.shuffle.partitions\", 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd31.sc:4</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    5 / 5\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd31.sc:4</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres31\u001b[39m: \u001b[32mArray\u001b[39m[(\u001b[32mString\u001b[39m, \u001b[32mList\u001b[39m[\u001b[32mInt\u001b[39m])] = \u001b[33mArray\u001b[39m(\n",
       "  (\u001b[32m\"b\"\u001b[39m, \u001b[33mList\u001b[39m(\u001b[32m3\u001b[39m, \u001b[32m5\u001b[39m)),\n",
       "  (\u001b[32m\"a\"\u001b[39m, \u001b[33mList\u001b[39m(\u001b[32m2\u001b[39m, \u001b[32m4\u001b[39m)),\n",
       "  (\u001b[32m\"d\"\u001b[39m, \u001b[33mList\u001b[39m(\u001b[32m4\u001b[39m))\n",
       ")"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "List((\"a\", 1), (\"b\", 2), (\"a\", 3), (\"d\", 3), (\"b\", 4)).toDS\n",
    "    .map{ case (key, value) => (key, value + 1) }\n",
    "    .groupByKey(_._1)\n",
    "    .mapGroups((key, values) => (key, values.toList.map(_._2)))\n",
    "    .collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can inspect the contents of the different partitions after each transformation:\n",
    "\n",
    "###### Para observar el contenido de cada particion `.collectPartitions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List((a,3), (d,3))\n",
      "List((e,2), (f,3))\n",
      "List((k,3), (i,3))\n",
      "List((l,2), (b,2))\n",
      "List((a,1))\n",
      "List((b,4), (e,4))\n",
      "List((d,3), (z,3))\n",
      "List((o,3))\n"
     ]
    }
   ],
   "source": [
    "List((\"a\", 1), (\"e\", 2), (\"f\", 3), (\"d\", 3), \n",
    "     (\"z\", 3), (\"k\", 3), (\"i\", 3), (\"o\", 3), \n",
    "     (\"l\",2), (\"b\", 2), (\"a\", 3), (\"d\", 3), \n",
    "     (\"b\", 4), (\"e\", 4)).toDS\n",
    "    .collectPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List((a,2))\n",
      "List((a,4), (d,4))\n",
      "List((o,4))\n",
      "List((e,3), (f,4))\n",
      "List((l,3), (b,3))\n",
      "List((k,4), (i,4))\n",
      "List((d,4), (z,4))\n",
      "List((b,5), (e,5))\n"
     ]
    }
   ],
   "source": [
    "List((\"a\", 1), (\"e\", 2), (\"f\", 3), (\"d\", 3), (\"z\", 3), (\"k\", 3), (\"i\", 3), (\"o\", 3), (\"l\",2), (\"b\", 2), (\"a\", 3), (\"d\", 3), (\"b\", 4), (\"e\", 4)).toDS\n",
    "    .map{ case (key, value) => (key, value + 1) }\n",
    "    .collectPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List((a,List(2, 4)))\n",
      "List((d,List(4, 4)), (e,List(3, 5)), (l,List(3)), (z,List(4)))\n",
      "List((b,List(3, 5)), (i,List(4)))\n",
      "List((f,List(4)), (k,List(4)), (o,List(4)))\n"
     ]
    }
   ],
   "source": [
    "List((\"a\", 1), (\"e\", 2), (\"f\", 3), (\"d\", 3), (\"z\", 3), (\"k\", 3), (\"i\", 3), (\"o\", 3), (\"l\",2), (\"b\", 2), (\"a\", 3), (\"d\", 3), (\"b\", 4), (\"e\", 4)).toDS\n",
    "    .map{ case (key, value) => (key, value + 1) }\n",
    "    .groupByKey(_._1)\n",
    "    .mapGroups((key, values) => (key, values.toList.map(_._2)))\n",
    "    .collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Narrow or wide?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The transformations in the Dataset API can be classified into narrow and wide transformations, systematically. We have already mentioned that `map` and `filter` belong to the former, and `groupByKey` to the latter. What about the following ones?\n",
    "\n",
    "###### Las transformaciones en la API de conjunto de datos se pueden clasificar en transformaciones estrechas y amplias, sistemticamente. Ya hemos mencionado que map y filter pertenecen a transformaciones estrechas y groupByKey a transformacion amplia. Qu pasa con los siguientes?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `coalesce`\n",
    "\n",
    "###### Para establecer el numero de particiones"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mds\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ds = List(1,2,2,3,4,4,5,6,4,7,3,8).toDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(7)\n",
      "List(5)\n",
      "List(6, 4)\n",
      "List(3, 8)\n",
      "List(3)\n",
      "List(4, 4)\n",
      "List(1)\n",
      "List(2, 2)\n"
     ]
    }
   ],
   "source": [
    "ds.collectPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    2 / 2\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(5, 6, 4, 7, 3, 8)\n",
      "List(1, 2, 2, 3, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "ds.coalesce(2).collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `dropDuplicates`\n",
    "\n",
    "###### Para eliminar los duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List()\n",
      "List(6)\n",
      "List()\n",
      "List(2, 4)\n",
      "List(5)\n",
      "List(8)\n",
      "List()\n",
      "List(1, 3, 7)\n"
     ]
    }
   ],
   "source": [
    "ds.dropDuplicates.collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `flatMap`\n",
    "\n",
    "###### El mtodo flatMap() es idntico al mtodo map(), pero la nica diferencia es que en flatMap se elimina la agrupacin interna de un elemento y se genera una secuencia.\n",
    "###### ----------------------------------------------------------------\n",
    "###### val name = Seq(\"Nidhi\", \"Singh\")\n",
    "###### val result1 = name.map(_.toLowerCase)\n",
    "###### Salida\n",
    "###### List(nidhi, singh)\n",
    "###### ----------------------------------------------------------------\n",
    "###### name.flatMap(_.toLowerCase)\n",
    "###### Salida\n",
    "###### List(n, i, d, h, i, s, i, n, g, h)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(7, -7)\n",
      "List(5, -5)\n",
      "List(6, -6, 4, -4)\n",
      "List(3, -3)\n",
      "List(2, -2, 2, -2)\n",
      "List(3, -3, 8, -8)\n",
      "List(1, -1)\n",
      "List(4, -4, 4, -4)\n"
     ]
    }
   ],
   "source": [
    "ds.flatMap(i => List(i, -i)).collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `limit`\n",
    "\n",
    "###### Maximo numero permitido el resto los quita"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    6 / 6\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(1)\n",
      "List(4)\n",
      "List(4)\n",
      "List(2)\n",
      "List(3)\n",
      "List(2)\n"
     ]
    }
   ],
   "source": [
    "ds.limit(6).collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `mapPartitions`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(2)\n",
      "List(8)\n",
      "List(7, 5)\n",
      "List(3, 3)\n",
      "List(6)\n",
      "List(5, 5)\n",
      "List(4, 9)\n",
      "List(4)\n"
     ]
    }
   ],
   "source": [
    "ds.mapPartitions{ it: Iterator[Int] => it.map(_ + 1) }.collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `repartition`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    2 / 2\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(2, 4, 4, 8)\n",
      "List(1, 2, 3, 4, 5, 6, 7, 3)\n"
     ]
    }
   ],
   "source": [
    "ds.repartition(2).collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compare it with `coalesce`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    2 / 2\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(1, 2, 2, 3, 4, 4)\n",
      "List(5, 6, 4, 7, 3, 8)\n"
     ]
    }
   ],
   "source": [
    "ds.coalesce(2).collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Differences can be \"explained\":"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Exchange RoundRobinPartitioning(2)\n",
      "+- LocalTableScan [value#169]\n"
     ]
    }
   ],
   "source": [
    "ds.repartition(2).explain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Coalesce 2\n",
      "+- LocalTableScan [value#169]\n"
     ]
    }
   ],
   "source": [
    "ds.coalesce(2).explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `sort`\n",
    "\n",
    "###### Ordena por valor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List()\n",
      "List(6)\n",
      "List(8)\n",
      "List(7)\n",
      "List(5)\n",
      "List(1, 2, 2)\n",
      "List(3, 3)\n",
      "List(4, 4, 4)\n"
     ]
    }
   ],
   "source": [
    "ds.sort(\"value\").collectPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd49.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd49.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">collect at cmd49.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres49\u001b[39m: \u001b[32mArray\u001b[39m[\u001b[32mInt\u001b[39m] = \u001b[33mArray\u001b[39m(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m2\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m3\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m4\u001b[39m, \u001b[32m5\u001b[39m, \u001b[32m6\u001b[39m, \u001b[32m7\u001b[39m, \u001b[32m8\u001b[39m)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds.sort(\"value\").collect"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What about transformations that relate several datasets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Commonly, information is spread across several datasets, and the Spark Dataset API includes transformations to deal with this situation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Union`\n",
    "\n",
    "###### Une todos los datos (particiones)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mds1\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]\r\n",
       "\u001b[36mds2\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ds1: Dataset[Int] = List(1,2,3,4).toDS.repartition(3)\n",
    "val ds2: Dataset[Int] = List(5,6,7,8).toDS.repartition(6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    3 / 3\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(4)\n",
      "List(3)\n",
      "List(1, 2)\n"
     ]
    }
   ],
   "source": [
    "ds1.collectPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    6 / 6\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List()\n",
      "List()\n",
      "List(8)\n",
      "List(7)\n",
      "List(5)\n",
      "List(6)\n"
     ]
    }
   ],
   "source": [
    "ds2.collectPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    9 / 9\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List()\n",
      "List(8)\n",
      "List()\n",
      "List(4)\n",
      "List(1, 2)\n",
      "List(3)\n",
      "List(5)\n",
      "List(7)\n",
      "List(6)\n"
     ]
    }
   ],
   "source": [
    "ds1.union(ds2).collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "No shuffle involved, just a single stage which makes the union of the different partitions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `Join`\n",
    "\n",
    "###### Une los datos a traves de la columna que le indicamos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "defined \u001b[32mobject\u001b[39m \u001b[36mDS\u001b[39m\r\n",
       "\u001b[32mimport \u001b[39m\u001b[36mDS._\u001b[39m"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "object DS{\n",
    "    case class Person(name: String, age: Int)\n",
    "    case class Student(name: String, degree: String, year: Int)\n",
    "}\n",
    "\n",
    "import DS._"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mpeople\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mPerson\u001b[39m] = [name: string, age: int]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val people: Dataset[Person] = List(\n",
    "    Person(\"Yihui\", 20),\n",
    "    Person(\"Noelia\", 19),\n",
    "    Person(\"Gabriel\", 22),\n",
    "    Person(\"Javier\", 21)).toDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mstudents\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mStudent\u001b[39m] = [name: string, degree: string ... 1 more field]"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val students: Dataset[Student] = List(\n",
    "    Student(\"Yihui\", \"II\", 2000),\n",
    "    Student(\"Yihui\", \"M\", 2001),\n",
    "    Student(\"Noelia\", \"II\", 2000),\n",
    "    Student(\"Noelia\", \"IS\", 2000),\n",
    "    Student(\"Gabriel\", \"II\", 2004),\n",
    "    Student(\"Javier\", \"II\", 2005),\n",
    "    Student(\"Javier\", \"M\", 2005)).toDS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(Person(Yihui,20))\n",
      "List(Person(Javier,21))\n",
      "List(Person(Gabriel,22))\n",
      "List(Person(Noelia,19))\n"
     ]
    }
   ],
   "source": [
    "people.collectPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    7 / 7\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List(Student(Noelia,IS,2000))\n",
      "List(Student(Yihui,M,2001))\n",
      "List(Student(Javier,II,2005))\n",
      "List(Student(Noelia,II,2000))\n",
      "List(Student(Javier,M,2005))\n",
      "List(Student(Yihui,II,2000))\n",
      "List(Student(Gabriel,II,2004))\n"
     ]
    }
   ],
   "source": [
    "students.collectPartitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">run at ThreadPoolExecutor.java:1128</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    7 / 7\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List([Javier,21,II,2005])\n",
      "List([Yihui,20,II,2000])\n",
      "List([Noelia,19,IS,2000])\n",
      "List([Noelia,19,II,2000])\n",
      "List([Javier,21,M,2005])\n",
      "List([Gabriel,22,II,2004])\n",
      "List([Yihui,20,M,2001])\n"
     ]
    }
   ],
   "source": [
    "people.join(students, \"name\").collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Somewhat unexpectedly, there is no shuffle! This is because Spark performs the join following a \"broadcast\" strategy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [name#241, age#242, degree#248, year#249]\n",
      "+- *(1) BroadcastHashJoin [name#241], [name#247], Inner, BuildLeft\n",
      "   :- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true]))\n",
      "   :  +- LocalTableScan [name#241, age#242]\n",
      "   +- LocalTableScan [name#247, degree#248, year#249]\n"
     ]
    }
   ],
   "source": [
    "people.join(students, \"name\").explain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This happens when one of the datasets is small enough to be copied for each partition. We can force Spark to avoid broadcast as follows (just for testing purposes): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\",0)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    7 / 7\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">foreachPartition at cmd25.sc:3</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "List()\n",
      "List()\n",
      "List()\n",
      "List()\n",
      "List([Noelia,19,II,2000], [Noelia,19,IS,2000])\n",
      "List([Gabriel,22,II,2004])\n",
      "List([Javier,21,II,2005], [Javier,21,M,2005])\n",
      "List([Yihui,20,II,2000], [Yihui,20,M,2001])\n"
     ]
    }
   ],
   "source": [
    "people.join(students, \"name\").collectPartitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching\n",
    "\n",
    "###### Con `.cache` guardamos los resultados/datos en cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One of the most distinctive features of Spark is its ability to cache computations of datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mds5\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ds5: Dataset[Int] = (0 to 1000).toDS.map(heavyComp(20))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd71.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd71.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4307\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd71.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd71.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4115\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres71_0\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m1001L\u001b[39m\r\n",
       "\u001b[36mres71_1\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m1001L\u001b[39m"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(ds5.count)\n",
    "run(ds5.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now with caching:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres72\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds5.cache"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd73.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd73.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4960\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd73.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd73.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 694\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres73_0\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m1001L\u001b[39m\r\n",
       "\u001b[36mres73_1\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m1001L\u001b[39m"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(ds5.count)\n",
    "run(ds5.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may instruct the Spark interpreter to not use cached data:\n",
    "\n",
    "###### Para que no usar el dato de la cache utilizamos `.unpersist`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mres74\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds5.unpersist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd75.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    8 / 8\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd75.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 4173\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres75\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m1001L\u001b[39m"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(ds5.count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The method `cache` is not a pure transformation but a side-effectful operation. It just instructs the Spark interpreter to cache the dataset as soon as it's executed.  \n",
    "\n",
    "###### `.cache` es una operacin secundaria. Simplemente indica al intrprete de Spark que almacene en cach el conjunto de datos tan pronto como se ejecute."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[36mds1\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]\r\n",
       "\u001b[36mds1_cached\u001b[39m: \u001b[32mDataset\u001b[39m[\u001b[32mInt\u001b[39m] = [value: int]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val ds1: Dataset[Int] = List(1,2,3,4).toDS.map(heavyComp())\n",
    "val ds1_cached: Dataset[Int] = ds1.cache"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We may expect that the only cached dataset is `ds1_cached`, but that's not true:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd77.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd77.sc:1</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 1576\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd77.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    4 / 4\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "  <span style=\"float: left;\">count at cmd77.sc:2</span>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div class=\"progress\">\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: blue; width: 100%; word-wrap: normal; white-space: nowrap; text-align: center; color: white\" aria-valuenow=\"100\" aria-valuemin=\"0\" aria-valuemax=\"100\">\n",
       "    1 / 1\n",
       "  </div>\n",
       "  <div class=\"progress-bar\" role=\"progressbar\" style=\"background-color: red; width: 0%\" aria-valuenow=\"0\" aria-valuemin=\"0\" aria-valuemax=\"100\"></div>\n",
       "</div>\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Took 342\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "\u001b[36mres77_0\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m4L\u001b[39m\r\n",
       "\u001b[36mres77_1\u001b[39m: \u001b[32mLong\u001b[39m = \u001b[32m4L\u001b[39m"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "run(ds1.count)\n",
    "run(ds1.count)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Scala",
   "language": "scala",
   "name": "scala"
  },
  "language_info": {
   "codemirror_mode": "text/x-scala",
   "file_extension": ".scala",
   "mimetype": "text/x-scala",
   "name": "scala",
   "nbconvert_exporter": "script",
   "version": "2.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
